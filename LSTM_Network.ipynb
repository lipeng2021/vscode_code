{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import time\n",
    "import zipfile\n",
    "import math\n",
    "import random\n",
    "import numpy as np\n",
    "device = torch.device('cuda' if torch.cuda.is_available()else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data_lyrics():\n",
    "    with zipfile.ZipFile('/home/data/jaychou_lyrics.txt.zip')as zin:\n",
    "        with zin.open('jaychou_lyrics.txt')as f:\n",
    "            corpus_chars = f.read().decode('utf-8')\n",
    "    corpus_chars = corpus_chars.replace('\\n',' ').replace('\\r',' ')\n",
    "    corpus_chars = corpus_chars[:10000]\n",
    "    idx_to_char = list(set(corpus_chars))\n",
    "    char_to_idx = dict([char,i]for i,char in enumerate(idx_to_char))\n",
    "    vocab_size =  len(idx_to_char)\n",
    "    corpus_iter = [char_to_idx[char]for char in corpus_chars]\n",
    "    return char_to_idx,idx_to_char,vocab_size,corpus_iter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "char_to_idx,idx_to_char,vocab_size,corpus_iter = load_data_lyrics()\n",
    "def data_iter_random(corpus_iter,batch_size,num_steps,device=None):\n",
    "    if device is None:\n",
    "        device = torch.device('cuda' if torch.cuda.is_available()else 'cpu')\n",
    "    num_example = (len(corpus_iter)-1)//num_steps\n",
    "    num_epochs = num_example//batch_size\n",
    "    example_iter = list(range(num_example))\n",
    "    random.shuffle(example_iter)\n",
    "    def _data(pos):\n",
    "        return corpus_iter[pos:pos+num_steps]\n",
    "    for i in range(num_epochs):\n",
    "        i = i*batch_size\n",
    "        batch_iter = example_iter[i:i+batch_size]\n",
    "        X = [_data(j*num_steps)for j in batch_iter]\n",
    "        Y = [_data(j*num_steps+1)for j in batch_iter]\n",
    "        x = torch.tensor(X,dtype=torch.float,device=device)\n",
    "        y = torch.tensor(Y,dtype=torch.float,device=device)\n",
    "        yield x,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[12., 13., 14., 15., 16., 17.],\n",
      "        [18., 19., 20., 21., 22., 23.]], device='cuda:0') tensor([[13., 14., 15., 16., 17., 18.],\n",
      "        [19., 20., 21., 22., 23., 24.]], device='cuda:0')\n",
      "tensor([[ 0.,  1.,  2.,  3.,  4.,  5.],\n",
      "        [ 6.,  7.,  8.,  9., 10., 11.]], device='cuda:0') tensor([[ 1.,  2.,  3.,  4.,  5.,  6.],\n",
      "        [ 7.,  8.,  9., 10., 11., 12.]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "x = list(range(30))\n",
    "for x,y in data_iter_random(x,2,6):\n",
    "    print(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_iter_consecution(corpus_iter,batch_size,num_steps,device=None):\n",
    "    if device is None:\n",
    "        device = torch.device('cuda' if torch.cuda.is_available()else 'cpu')\n",
    "    data_len = len(corpus_iter)\n",
    "    num_batch = data_len // batch_size\n",
    "    corpus_iter = torch.tensor(corpus_iter,dtype=torch.float32,device=device)\n",
    "    iteration = corpus_iter[0:num_batch*batch_size].view(batch_size,num_batch)\n",
    "    num_epochs = (num_batch-1)//num_steps\n",
    "    for i in range(num_epochs):\n",
    "        i = i *num_steps\n",
    "        x = iteration[:,i:i+num_steps]\n",
    "        y = iteration[:,i+1:i+num_steps+1]\n",
    "        yield x,y "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def onehot(x,n_class,dtype=torch.float32):\n",
    "    x = x.long()\n",
    "    res = torch.zeros(x.shape[0],n_class,dtype=dtype,device=x.device)\n",
    "    res.scatter_(1,x.view(-1,1),1)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_onehot(x,n_class):\n",
    "    return [onehot(x[:,i],n_class)for i in range(x.shape[1])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 1., 0., 0., 0., 0.]]),\n",
       " tensor([[0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 1., 0., 0., 0.]]),\n",
       " tensor([[0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 1., 0., 0.]]),\n",
       " tensor([[0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 1., 0.]]),\n",
       " tensor([[0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]])]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.arange(10).view(2,5)\n",
    "to_onehot(x,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_inputs,num_hiddens,num_outputs = vocab_size,256,vocab_size\n",
    "def get_params():\n",
    "    def _one(shape):\n",
    "        ts = torch.tensor(np.random.normal(0,0.01,size=shape),dtype=torch.float32,device=device)\n",
    "        return torch.nn.Parameter(ts,requires_grad=True)\n",
    "    def _three():\n",
    "        return (\n",
    "            _one((num_inputs,num_hiddens)),\n",
    "            _one((num_hiddens,num_hiddens)),\n",
    "            torch.nn.Parameter(torch.zeros(num_hiddens,dtype=torch.float32,device=device),requires_grad=True)\n",
    "        )\n",
    "    w_xf,w_hf,b_f = _three()\n",
    "    w_xi,w_hi,b_i = _three()\n",
    "    w_xo,w_ho,b_o = _three()\n",
    "\n",
    "    w_xc,w_hc,b_c = _three()\n",
    "    w_h = _one((num_hiddens,num_outputs))\n",
    "    b_h = nn.Parameter(torch.zeros(num_outputs,device=device,dtype=torch.float32),requires_grad=True)\n",
    "    return nn.ParameterList([ w_xf,w_hf,b_f,w_xi,w_hi,b_i,w_xo,w_ho,b_o,w_xc,w_hc,b_c,w_h,b_h])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_state_lstm(batch_size,num_hiddens,device):\n",
    "    return (torch.zeros((batch_size,num_hiddens),device=device),\n",
    "            torch.zeros((batch_size,num_hiddens),device=device)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LSTM(inputs,state,params):\n",
    "    w_xf,w_hf,b_f,w_xi,w_hi,b_i,w_xo,w_ho,b_o,w_xc,w_hc,b_c,w_h,b_h = params\n",
    "    H,C = state\n",
    "    outputs = []\n",
    "    for x in inputs:\n",
    "        F = torch.matmul(x,w_xf)+torch.matmul(H,w_hf)+b_f\n",
    "        F = torch.sigmoid(F)\n",
    "        I = torch.matmul(x,w_xi)+torch.matmul(H,w_hi)+b_i\n",
    "        I = torch.sigmoid(I)\n",
    "        O = torch.matmul(x,w_xo)+torch.matmul(H,w_ho)+b_o\n",
    "        O = torch.sigmoid(O)\n",
    "        c_tilda = torch.matmul(x,w_xc)+torch.matmul(H,w_hc)+b_c\n",
    "        c_tilda = torch.tanh(c_tilda)\n",
    "        C = F*C + I*c_tilda\n",
    "        H = O*torch.tanh(C)\n",
    "        output = torch.matmul(H,w_h)+b_h\n",
    "        outputs.append(output)\n",
    "    return outputs,(H,C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pred_LSTM(prefix,num_chars,lstm,params,init,num_hiddens,vocab_size,idx_to_char,char_to_idx):\n",
    "    state = init(1,num_hiddens,device)\n",
    "    outputs = [char_to_idx[prefix[0]]]\n",
    "    for t in range(num_chars+len(prefix)-1):\n",
    "        X = to_onehot(torch.tensor([[outputs[-1]]],device=device),vocab_size)\n",
    "        output,state  = LSTM(X,state,params)\n",
    "        if t<len(prefix)-1:\n",
    "            outputs.append(char_to_idx[prefix[t+1]])\n",
    "        else:\n",
    "            outputs.append(int(output[0].argmax(dim=1).item()))\n",
    "    return ''.join([idx_to_char[i]for i in outputs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'分开阻辈可欢消苏中土蟑抢'"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prefix = '分开'\n",
    "params=get_params()\n",
    "init = init_state_lstm\n",
    "pred_LSTM(prefix,10,LSTM,params,init,num_hiddens,vocab_size,idx_to_char,char_to_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clip_gradient(params,theta,device):\n",
    "    norm = torch.tensor([0.0],device=device)\n",
    "    for param in params:\n",
    "        norm += (param.grad.data**2).sum()\n",
    "    norm = norm.sqrt().item()\n",
    "    if norm>theta:\n",
    "        for param in params:\n",
    "            param.grad.data *= (theta/norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sgd(param,lr,batch_size):\n",
    "    for param in params:\n",
    "        param.data -=(param.grad*lr)/batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_pred_lstm(net,params,init,num_epochs,num_hiddens,\n",
    "lr,num_steps,batch_size,is_iter_random,device,clipping_rate,\n",
    "idx_to_char,char_to_idx,corpus_iter,pred_period,vocab_size,\n",
    "pred_len,prefixes):\n",
    "    loss = nn.CrossEntropyLoss()\n",
    "    if is_iter_random:\n",
    "        data_iter_fn = data_iter_random\n",
    "    else:\n",
    "        data_iter_fn = data_iter_consecution\n",
    "    for epoch in range(num_epochs):\n",
    "        if not is_iter_random:\n",
    "            state = init(batch_size,num_hiddens,device)\n",
    "        l_sum = 0.0\n",
    "        n = 0\n",
    "        start = time.time()\n",
    "        data_iter = data_iter_fn(corpus_iter,batch_size,num_steps,device)\n",
    "        for X,Y in data_iter:\n",
    "            if is_iter_random:\n",
    "                state = init(batch_size,num_hiddens,device)\n",
    "            else:\n",
    "                for s in state:\n",
    "                    s.detach()\n",
    "            if state is not None:\n",
    "                if isinstance(state,tuple):\n",
    "                    state = (state[0].detach(),state[1].detach())\n",
    "                else:\n",
    "                    state = state.detach()\n",
    "            inputs = to_onehot(X,vocab_size)\n",
    "            y_hat,state = net(inputs,state,params)\n",
    "            y_hat = torch.cat(y_hat,dim=0)\n",
    "            y = torch.transpose(Y,0,1).contiguous().view(-1)\n",
    "            l = loss(y_hat,y.long())\n",
    "            if params[0].grad is not None:\n",
    "                for param in params:\n",
    "                    param.grad.data.zero_()\n",
    "            l.backward()\n",
    "            clip_gradient(params,clipping_rate,device)\n",
    "            sgd(params,lr,1)\n",
    "            l_sum +=l.item()*y.shape[0]\n",
    "            n += y.shape[0]\n",
    "        if (epoch+1)%pred_period==0:\n",
    "            print('Epoch:%d,pre:%.3f,time:%.1f'%(epoch+1,math.exp(l_sum/n),time.time()-start))\n",
    "            for prefix in prefixes:\n",
    "                print('---',pred_LSTM(prefix,pred_len,net,params,init,num_hiddens,vocab_size,idx_to_char,char_to_idx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:50,pre:51.900,time:0.3\n",
      "--- 分开 我想你 你不的我不着 我想不着 我不的我不着 一色在 干不了 我不了 有不么 我的在 我的的在 你\n",
      "--- 不分开 我想我我不着 我不不的 我不了的爱爱 一不么 干什了 我不了这不棍 一色在在 快什了空 我不么 不\n",
      "Epoch:100,pre:13.584,time:0.3\n",
      "--- 分开 一说我 你着我的手 说  你很很的吧? 我不着你想想 我  我 说眼眼睛看着我 别发抖 快给我抬起\n",
      "--- 不分开 你想我 我不么 我说么 我说就 我想就 我不能 我不能 我不走 我不风 旧再风 旧说风 说说梦 说\n",
      "Epoch:150,pre:4.120,time:0.3\n",
      "--- 分开 一直你 你来的手的手 说通 却想再考倒我?? 我给你的黑色幽 说不到我的路堡 就是是童了故每  有\n",
      "--- 不分开 你来定么不着我 甩是我的手腔幽 在不去了了嵩山 学少林跟武嵩 快使用双截棍 哼哼哈兮 快使用双截棍\n",
      "Epoch:200,pre:2.119,time:0.3\n",
      "--- 分开 一直说 你不眼的玩笑 我通啊 是又考倒倒我 说散 你想很久了吧? 败给你的黑色幽默 不散 你想很久\n",
      "--- 不分开 你在经么开我 不开 看又我的倒活 说散 你又很久了吧? 我给去拆黑色幽幽 说散 你想很久了吧? 我\n",
      "Epoch:250,pre:1.471,time:0.3\n",
      "--- 分开 一轻说 你你的玩前 喜师 他念念 有词的 对酋我 才酋开我 我变就很主 这你是我 你过了一演出 一\n",
      "--- 不分开 你作经开开我 不开开觉不手 抛这线进们 单过过人球 篮下妙传 手手了这节奏 篮知后觉 手人了人过秋\n"
     ]
    }
   ],
   "source": [
    "num_epochs =250\n",
    "num_steps = 35\n",
    "batch_size = 32\n",
    "lr = 1e2\n",
    "clipping_rate = 1e-2\n",
    "pred_period = 50\n",
    "pred_len = 50\n",
    "prefixes = ['分开','不分开']\n",
    "train_and_pred_lstm(LSTM,params,init,num_epochs,num_hiddens,lr,num_steps,batch_size,False,\n",
    "device,clipping_rate,idx_to_char,char_to_idx,corpus_iter,pred_period,vocab_size,pred_len,prefixes)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "2f394aca7ca06fed1e6064aef884364492d7cdda3614a461e02e6407fc40ba69"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
