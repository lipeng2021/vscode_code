{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import time\n",
    "import zipfile\n",
    "import math\n",
    "import random\n",
    "import numpy as np\n",
    "device = torch.device('cuda' if torch.cuda.is_available()else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data_lyrics():\n",
    "    with zipfile.ZipFile('/home/data/jaychou_lyrics.txt.zip')as zin:\n",
    "        with zin.open('jaychou_lyrics.txt')as f:\n",
    "            corpus_chars = f.read().decode('utf-8')\n",
    "    corpus_chars = corpus_chars.replace('\\n',' ').replace('\\r',' ')\n",
    "    corpus_chars = corpus_chars[:10000]\n",
    "    idx_to_char = list(set(corpus_chars))\n",
    "    char_to_idx = dict([char,i]for i,char in enumerate(idx_to_char))\n",
    "    vocab_size =  len(idx_to_char)\n",
    "    corpus_iter = [char_to_idx[char]for char in corpus_chars]\n",
    "    return char_to_idx,idx_to_char,vocab_size,corpus_iter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "char_to_idx,idx_to_char,vocab_size,corpus_iter = load_data_lyrics()\n",
    "def data_iter_random(corpus_iter,batch_size,num_steps,device=None):\n",
    "    if device is None:\n",
    "        device = torch.device('cuda' if torch.cuda.is_available()else 'cpu')\n",
    "    num_example = (len(corpus_iter)-1)//num_steps\n",
    "    num_epochs = num_example//batch_size\n",
    "    example_iter = list(range(num_example))\n",
    "    random.shuffle(example_iter)\n",
    "    def _data(pos):\n",
    "        return corpus_iter[pos:pos+num_steps]\n",
    "    for i in range(num_epochs):\n",
    "        i = i*batch_size\n",
    "        batch_iter = example_iter[i:i+batch_size]\n",
    "        X = [_data(j*num_steps)for j in batch_iter]\n",
    "        Y = [_data(j*num_steps+1)for j in batch_iter]\n",
    "        x = torch.tensor(X,dtype=torch.float,device=device)\n",
    "        y = torch.tensor(Y,dtype=torch.float,device=device)\n",
    "        yield x,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 6.,  7.,  8.,  9., 10., 11.],\n",
      "        [12., 13., 14., 15., 16., 17.]], device='cuda:0') tensor([[ 7.,  8.,  9., 10., 11., 12.],\n",
      "        [13., 14., 15., 16., 17., 18.]], device='cuda:0')\n",
      "tensor([[ 0.,  1.,  2.,  3.,  4.,  5.],\n",
      "        [18., 19., 20., 21., 22., 23.]], device='cuda:0') tensor([[ 1.,  2.,  3.,  4.,  5.,  6.],\n",
      "        [19., 20., 21., 22., 23., 24.]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "x = list(range(30))\n",
    "for x,y in data_iter_random(x,2,6):\n",
    "    print(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_iter_consecution(corpus_iter,batch_size,num_steps,device=None):\n",
    "    if device is None:\n",
    "        device = torch.device('cuda' if torch.cuda.is_available()else 'cpu')\n",
    "    data_len = len(corpus_iter)\n",
    "    num_batch = data_len // batch_size\n",
    "    corpus_iter = torch.tensor(corpus_iter,dtype=torch.float32,device=device)\n",
    "    iteration = corpus_iter[0:num_batch*batch_size].view(batch_size,num_batch)\n",
    "    num_epochs = (num_batch-1)//num_steps\n",
    "    for i in range(num_epochs):\n",
    "        i = i *num_steps\n",
    "        x = iteration[:,i:i+num_steps]\n",
    "        y = iteration[:,i+1:i+num_steps+1]\n",
    "        yield x,y "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def onehot(x,n_class,dtype=torch.float32):\n",
    "    x = x.long()\n",
    "    res = torch.zeros(x.shape[0],n_class,dtype=dtype,device=x.device)\n",
    "    res.scatter_(1,x.view(-1,1),1)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_onehot(x,n_class):\n",
    "    return [onehot(x[:,i],n_class)for i in range(x.shape[1])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 1., 0., 0., 0., 0.]]),\n",
       " tensor([[0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 1., 0., 0., 0.]]),\n",
       " tensor([[0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 1., 0., 0.]]),\n",
       " tensor([[0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 1., 0.]]),\n",
       " tensor([[0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]])]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.arange(10).view(2,5)\n",
    "to_onehot(x,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_inputs,num_hiddens,num_outputs = vocab_size,256,vocab_size\n",
    "def get_params():\n",
    "    def _one(shape):\n",
    "        ts = torch.tensor(np.random.normal(0,0.01,size=shape),dtype=torch.float32,device=device)\n",
    "        return torch.nn.Parameter(ts,requires_grad=True)\n",
    "    def _three():\n",
    "        return (\n",
    "            _one((num_inputs,num_hiddens)),\n",
    "            _one((num_hiddens,num_hiddens)),\n",
    "            torch.nn.Parameter(torch.zeros(num_hiddens,dtype=torch.float32,device=device),requires_grad=True)\n",
    "        )\n",
    "    w_xf,w_hf,b_f = _three()\n",
    "    w_xi,w_hi,b_i = _three()\n",
    "    w_xo,w_ho,b_o = _three()\n",
    "\n",
    "    w_xc,w_hc,b_c = _three()\n",
    "    w_h = _one((num_hiddens,num_outputs))\n",
    "    b_h = nn.Parameter(torch.zeros(num_outputs,device=device,dtype=torch.float32),requires_grad=True)\n",
    "    return nn.ParameterList([ w_xf,w_hf,b_f,w_xi,w_hi,b_i,w_xo,w_ho,b_o,w_xc,w_hc,b_c,w_h,b_h])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_state_lstm(batch_size,num_hiddens,device):\n",
    "    return (torch.zeros((batch_size,num_hiddens),device=device),\n",
    "            torch.zeros((batch_size,num_hiddens),device=device)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LSTM(inputs,state,params):\n",
    "    w_xf,w_hf,b_f,w_xi,w_hi,b_i,w_xo,w_ho,b_o,w_xc,w_hc,b_c,w_h,b_h = params\n",
    "    H,C = state\n",
    "    outputs = []\n",
    "    for x in inputs:\n",
    "        F = torch.matmul(x,w_xf)+torch.matmul(H,w_hf)+b_f\n",
    "        F = torch.sigmoid(F)\n",
    "        I = torch.matmul(x,w_xi)+torch.matmul(H,w_hi)+b_i\n",
    "        I = torch.sigmoid(I)\n",
    "        O = torch.matmul(x,w_xo)+torch.matmul(H,w_ho)+b_o\n",
    "        O = torch.sigmoid(O)\n",
    "        c_tilda = torch.matmul(x,w_xc)+torch.matmul(H,w_hc)+b_c\n",
    "        c_tilda = torch.tanh(c_tilda)\n",
    "        C = F*C + I*c_tilda\n",
    "        H = O*torch.tanh(C)\n",
    "        output = torch.matmul(H,w_h)+b_h\n",
    "        outputs.append(output)\n",
    "    return outputs,(H,C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pred_LSTM(prefix,num_chars,lstm,params,init,num_hiddens,vocab_size,idx_to_char,char_to_idx):\n",
    "    state = init(1,num_hiddens,device)\n",
    "    outputs = [char_to_idx[prefix[0]]]\n",
    "    for t in range(num_chars+len(prefix)-1):\n",
    "        X = to_onehot(torch.tensor([[outputs[-1]]],device=device),vocab_size)\n",
    "        output,state  = LSTM(X,state,params)\n",
    "        if t<len(prefix)-1:\n",
    "            outputs.append(char_to_idx[prefix[t+1]])\n",
    "        else:\n",
    "            outputs.append(int(output[0].argmax(dim=1).item()))\n",
    "    return ''.join([idx_to_char[i]for i in outputs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'分开弃霜烁根容闭状根整界'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prefix = '分开'\n",
    "params=get_params()\n",
    "init = init_state_lstm\n",
    "pred_LSTM(prefix,10,LSTM,params,init,num_hiddens,vocab_size,idx_to_char,char_to_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clip_gradient(params,theta,device):\n",
    "    norm = torch.tensor([0.0],device=device)\n",
    "    for param in params:\n",
    "        norm += (param.grad.data**2).sum()\n",
    "    norm = norm.sqrt().item()\n",
    "    if norm>theta:\n",
    "        for param in params:\n",
    "            param.grad.data *= (theta/norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sgd(param,lr,batch_size):\n",
    "    for param in params:\n",
    "        param.data -=(param.grad*lr)/batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_pred_lstm(net,params,init,num_epochs,num_hiddens,\n",
    "lr,num_steps,batch_size,is_iter_random,device,clipping_rate,\n",
    "idx_to_char,char_to_idx,corpus_iter,pred_period,vocab_size,\n",
    "pred_len,prefixes):\n",
    "    loss = nn.CrossEntropyLoss()\n",
    "    if is_iter_random:\n",
    "        data_iter_fn = data_iter_random\n",
    "    else:\n",
    "        data_iter_fn = data_iter_consecution\n",
    "    for epoch in range(num_epochs):\n",
    "        if not is_iter_random:\n",
    "            state = init(batch_size,num_hiddens,device)\n",
    "        l_sum = 0.0\n",
    "        n = 0\n",
    "        start = time.time()\n",
    "        data_iter = data_iter_fn(corpus_iter,batch_size,num_steps,device)\n",
    "        for X,Y in data_iter:\n",
    "            if is_iter_random:\n",
    "                state = init(batch_size,num_hiddens,device)\n",
    "            else:\n",
    "                for s in state:\n",
    "                    s.detach()\n",
    "            if state is not None:\n",
    "                if isinstance(state,tuple):\n",
    "                    state = (state[0].detach(),state[1].detach())\n",
    "                else:\n",
    "                    state = state.detach()\n",
    "            inputs = to_onehot(X,vocab_size)\n",
    "            y_hat,state = net(inputs,state,params)\n",
    "            y_hat = torch.cat(y_hat,dim=0)\n",
    "            y = torch.transpose(Y,0,1).contiguous().view(-1)\n",
    "            l = loss(y_hat,y.long())\n",
    "            if params[0].grad is not None:\n",
    "                for param in params:\n",
    "                    param.grad.data.zero_()\n",
    "            l.backward()\n",
    "            clip_gradient(params,clipping_rate,device)\n",
    "            sgd(params,lr,1)\n",
    "            l_sum +=l.item()*y.shape[0]\n",
    "            n += y.shape[0]\n",
    "        if (epoch+1)%pred_period==0:\n",
    "            print('Epoch:%d,pre:%.3f,time:%.1f'%(epoch+1,math.exp(l_sum/n),time.time()-start))\n",
    "            for prefix in prefixes:\n",
    "                print('---',pred_LSTM(prefix,pred_len,net,params,init,num_hiddens,vocab_size,idx_to_char,char_to_idx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:50,pre:162.488,time:0.2\n",
      "--- 分开 我不的我 我不不 我不不 我不不 我不不 我不不 我不不 我不不 我不不 我不不 我不不 我不不 \n",
      "--- 不分开 我想你你的我 我想不你 我不不 我不不 我不不 我不不 我不不 我不不 我不不 我不不 我不不 我\n",
      "Epoch:100,pre:33.983,time:0.3\n",
      "--- 分开 我想你你的微笑 一一  说想你的你有 一话  说想我的你有 有你  说你我的你有 有你 我想你的你\n",
      "--- 不分开 我不你这已我有一一悲 我想想你的爱笑 你你 我想想的我有你 我想想你的爱笑 我想要 你不我 我不要\n",
      "Epoch:150,pre:6.094,time:0.3\n",
      "--- 分开 我想带这生经 一个个人 不来一直 我不就的抽 我面放好 全没用空 不人不动 没没有没 没有放纵 没\n",
      "--- 不分开 我不经这生我 不要不觉 我跟了这节奏 后知后觉 又过了一个秋 后知后觉 我该好好生活 我该好好生活\n",
      "Epoch:200,pre:1.891,time:0.3\n",
      "--- 分开 我已带这生嵩 就你依 一直走的我想就你在一着  为知来起起个大不住 不懂 你的黑色幽默 想通 却又\n",
      "--- 不分开 我已经这生单 我想能 你爱我 我想要这样布 对你依依不舍 连隔壁邻居都猜到我现在的感受 河边的风 \n",
      "Epoch:250,pre:1.228,time:0.3\n",
      "--- 分开 我轻轻的话快 后着着对不起 藤蔓植物 爬满了伯爵的坟墓 古堡里一片荒芜 长满杂草的泥土 不会骑扫把\n",
      "--- 不分开 你已经离开我 不知不觉 我跟了这节奏 后知后觉 又过了一个秋 后知后觉 我该好好生活 我该好好生活\n"
     ]
    }
   ],
   "source": [
    "num_epochs =250\n",
    "num_steps = 35\n",
    "batch_size = 32\n",
    "lr = 1e2\n",
    "clipping_rate = 1e-2\n",
    "pred_period = 50\n",
    "pred_len = 50\n",
    "prefixes = ['分开','不分开']\n",
    "train_and_pred_lstm(LSTM,params,init,num_epochs,num_hiddens,lr,num_steps,batch_size,False,\n",
    "device,clipping_rate,idx_to_char,char_to_idx,corpus_iter,pred_period,vocab_size,pred_len,prefixes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sat Apr 30 09:10:56 2022       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 510.60.02    Driver Version: 510.60.02    CUDA Version: 11.6     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  NVIDIA RTX A5000    On   | 00000000:25:00.0 Off |                  Off |\n",
      "| 30%   33C    P8    15W / 230W |   2209MiB / 24564MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|    0   N/A  N/A    771508      C                                    2207MiB |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "2f394aca7ca06fed1e6064aef884364492d7cdda3614a461e02e6407fc40ba69"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
