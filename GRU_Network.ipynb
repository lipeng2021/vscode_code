{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import time\n",
    "import random\n",
    "import math\n",
    "import zipfile\n",
    "import numpy as np\n",
    "device = torch.device('cuda' if torch.cuda.is_available()else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[219, 572, 181, 62, 961, 928, 275, 219, 572, 819]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def load_data_lyrics():\n",
    "    with zipfile.ZipFile('/home/data/jaychou_lyrics.txt.zip') as zin:\n",
    "        with zin.open('jaychou_lyrics.txt')as f:\n",
    "            corpus_chars = f.read().decode('utf-8')\n",
    "    corpus_chars = corpus_chars.replace('\\n',' ').replace('\\r',' ')\n",
    "    corpus_chars = corpus_chars[:10000]\n",
    "    idx_to_char = list(set(corpus_chars))\n",
    "    char_to_idx = dict([[char,i]for i,char in enumerate(idx_to_char)])\n",
    "    vocab_size = len(idx_to_char)\n",
    "    corpus_iter = [char_to_idx[char]for char in corpus_chars]\n",
    "    return idx_to_char,char_to_idx,vocab_size,corpus_iter\n",
    "idx_to_char,char_to_idx,vocab_size,corpus_iter = load_data_lyrics()\n",
    "corpus_iter[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_iter_random(corpus_iter,batch_size,num_steps,device=None):\n",
    "    if device is None:\n",
    "        device = torch.device('cuda' if torch.cuda.is_available()else 'cpu')\n",
    "    num_examples = (len(corpus_iter)-1)//num_steps\n",
    "    num_epochs = num_examples//batch_size\n",
    "    example_iter = list(range(num_examples))\n",
    "    random.shuffle(example_iter)\n",
    "    def _data(pos):\n",
    "        return corpus_iter[pos:pos+num_steps]\n",
    "    for i in range(num_epochs):\n",
    "        i = i*batch_size\n",
    "        batch_iter = example_iter[i:i+batch_size]\n",
    "        X = [_data(j*num_steps)for j in batch_iter]\n",
    "        Y = [_data(j*num_steps+1)for j in batch_iter]\n",
    "        yield torch.tensor(X,dtype=torch.float32,device=device),torch.tensor(Y,dtype=torch.float32,device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29]\n",
      "tensor([[18., 19., 20., 21., 22., 23.],\n",
      "        [ 6.,  7.,  8.,  9., 10., 11.]], device='cuda:0') tensor([[19., 20., 21., 22., 23., 24.],\n",
      "        [ 7.,  8.,  9., 10., 11., 12.]], device='cuda:0')\n",
      "tensor([[ 0.,  1.,  2.,  3.,  4.,  5.],\n",
      "        [12., 13., 14., 15., 16., 17.]], device='cuda:0') tensor([[ 1.,  2.,  3.,  4.,  5.,  6.],\n",
      "        [13., 14., 15., 16., 17., 18.]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "x = list(range(30))\n",
    "print(x)\n",
    "for X,Y in data_iter_random(x,2,6):\n",
    "    print(X,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_iter_consecution(corpus_iter,batch_size,num_steps,device=None):\n",
    "    if device is None:\n",
    "        device = torch.device('cuda' if torch.cuda.is_available()else 'cpu')\n",
    "    corpus_iter = torch.tensor(corpus_iter,dtype=torch.float32,device=device)\n",
    "    data_len = len(corpus_iter)\n",
    "    num_batch = data_len//batch_size\n",
    "    iteration = corpus_iter[0:batch_size*num_batch].view(batch_size,num_batch)\n",
    "    num_epochs = (num_batch-1)//num_steps\n",
    "    for i in range(num_epochs):\n",
    "        i = i *num_steps\n",
    "        x = iteration[:,i:i+num_steps]\n",
    "        y = iteration[:,i+1:i+num_steps+1]\n",
    "        yield x,y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29]\n",
      "tensor([[ 0.,  1.,  2.,  3.,  4.,  5.],\n",
      "        [15., 16., 17., 18., 19., 20.]], device='cuda:0') tensor([[ 1.,  2.,  3.,  4.,  5.,  6.],\n",
      "        [16., 17., 18., 19., 20., 21.]], device='cuda:0')\n",
      "tensor([[ 6.,  7.,  8.,  9., 10., 11.],\n",
      "        [21., 22., 23., 24., 25., 26.]], device='cuda:0') tensor([[ 7.,  8.,  9., 10., 11., 12.],\n",
      "        [22., 23., 24., 25., 26., 27.]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "x = list(range(30))\n",
    "print(x)\n",
    "for X,Y in data_iter_consecution(x,2,6):\n",
    "    print(X,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def onehot(x,n_class,dtype=torch.float32):\n",
    "    x = x.long()\n",
    "    res = torch.zeros(x.shape[0],n_class,dtype=torch.float32,device=x.device)\n",
    "    res.scatter_(1,x.view(-1,1),1)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_onehot(x,n_class):\n",
    "    return [onehot(x[:,i],n_class)for i in range(x.shape[1])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_inputs,num_hiddens,num_outputs = vocab_size,256,vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_params():\n",
    "    def _one(shape):\n",
    "        ts = torch.tensor(np.random.normal(0,0.01,size=shape),dtype=torch.float32,device=device)\n",
    "        return nn.Parameter(ts,requires_grad=True)\n",
    "    def _three():\n",
    "       return ( _one((num_inputs,num_hiddens)),\n",
    "                _one((num_hiddens,num_hiddens)),\n",
    "                nn.Parameter(torch.zeros(num_hiddens,device=device,dtype=torch.float32),requires_grad=True))\n",
    "    w_xz,w_hz,b_z = _three()\n",
    "    w_xr,w_hr,b_r = _three()\n",
    "    w_xh,w_hh,b_h = _three()\n",
    "    \n",
    "    w_hq = _one((num_hiddens,num_outputs))\n",
    "    b_q = nn.Parameter(torch.zeros(num_outputs,device=device,dtype=torch.float32),requires_grad=True)\n",
    "    \n",
    "    return nn.ParameterList([w_xz,w_hz,b_z,w_xr,w_hr,b_r, w_xh,w_hh,b_h,w_hq,b_q])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_gru_states(batch_size,num_hiddens,device):\n",
    "    return (torch.zeros((batch_size,num_hiddens),device=device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GRU(inputs,state,params):\n",
    "    w_xz,w_hz,b_z,w_xr,w_hr,b_r, w_xh,w_hh,b_h,w_hq,b_q= params\n",
    "    H = state\n",
    "    outputs = []\n",
    "    for x in inputs:\n",
    "        R = torch.matmul(x,w_xr)+torch.matmul(H,w_hr)+b_r\n",
    "        R = torch.sigmoid(R)\n",
    "        Z = torch.matmul(x,w_xz)+torch.matmul(H,w_hz)+b_z\n",
    "        Z = torch.sigmoid(Z)\n",
    "        H_tilda = torch.matmul(x,w_xh)+R*torch.matmul(H,w_hh)+b_h\n",
    "        H_tilda = torch.tanh(H_tilda)\n",
    "        H = Z*H +(1-Z)*H_tilda\n",
    "        Y = torch.matmul(H,w_hq)+b_q\n",
    "        outputs.append(Y)\n",
    "    return outputs,H"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pred_gru(prefil,gru,num_chars,params,init_gru_states,num_hiddens,vocab_size,device,idx_to_char,char_to_idx):\n",
    "    state = init_gru_states(1,num_hiddens,device)\n",
    "    output = [char_to_idx[prefil[0]]]\n",
    "    for t in range(num_chars+len(prefil)-1):\n",
    "        x = to_onehot(torch.tensor([[output[-1]]],device=device),vocab_size)\n",
    "        (Y,state) = gru(x,state,params)\n",
    "        if t<len(prefil)-1:\n",
    "            output.append(char_to_idx[prefil[t+1]])\n",
    "        else:\n",
    "            output.append(int(Y[0].argmax(dim=1).item()))\n",
    "    return ''.join([idx_to_char[i]for i in output])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'分开耳熟手格格元站因诉词'"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prefil='分开'\n",
    "params = get_params()\n",
    "pred_gru(prefil,GRU,10,params,init_gru_states,num_hiddens,vocab_size,device,idx_to_char,char_to_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clip_gradient(params,theta,device):\n",
    "    norm = torch.tensor([0.0],device=device)\n",
    "    for param in params:\n",
    "        norm += (param.grad.data**2).sum()\n",
    "    norm = norm.sqrt().item()\n",
    "    if norm > theta:\n",
    "        for param in params:\n",
    "            param.grad.data *=(theta/norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sgd(params,lr,batch_size):\n",
    "    for param in params:\n",
    "        param.data -=(lr*param.grad)/batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_pred_GRU(gru,get_params,init_gru_states,num_hiddens,vocab_size,device,corpus_iter,char_to_idx,idx_to_char,is_data_random,num_epochs,num_steps,lr,clipping_theta,batch_size,pred_period,pred_len,prefixes):\n",
    "    loss = nn.CrossEntropyLoss()\n",
    "    if is_data_random:\n",
    "        data_iter_fn = data_iter_random\n",
    "    else:\n",
    "        data_iter_fn = data_iter_consecution\n",
    "    params = get_params()   \n",
    "    for epoch in range(num_epochs):\n",
    "        if not is_data_random:\n",
    "            state = init_gru_states(batch_size,num_hiddens,device)\n",
    "        l_sum = 0.0\n",
    "        n =0 \n",
    "        start = time.time()\n",
    "        data_iter = data_iter_fn(corpus_iter,batch_size,num_steps,device)\n",
    "        for X,Y in data_iter:\n",
    "            if state is not None:\n",
    "                if isinstance(state,tuple):\n",
    "                    state = (state[0].detach(),state[1].detach())\n",
    "                else:\n",
    "                    state = state.detach()\n",
    "            if is_data_random:\n",
    "                state = init_gru_states(batch_size,num_hiddens,device)\n",
    "            else:\n",
    "                for s in state:\n",
    "                    s.detach()\n",
    "            inputs = to_onehot(X,vocab_size) \n",
    "            y_hat,state= gru(inputs,state,params)\n",
    "            y_hat = torch.cat(y_hat,dim=0)\n",
    "            Y = torch.transpose(Y,0,1).contiguous().view(-1)\n",
    "            l = loss(y_hat,Y.long())\n",
    "            if params[0].grad is not None:\n",
    "                for param in params:\n",
    "                    param.grad.data.zero_()\n",
    "            l.backward()\n",
    "            clip_gradient(params,clipping_theta,device)\n",
    "            sgd(params,lr,1)\n",
    "            l_sum += l.item()*Y.shape[0]\n",
    "            n += Y.shape[0]\n",
    "        if (epoch+1)% pred_period ==0:\n",
    "            print('epoch:%d,pre:%.5f,time:%.f'%(epoch+1,math.exp(l_sum/n),time.time()-start))\n",
    "            for prefix in prefixes:\n",
    "                print('---',pred_gru(prefix,gru,pred_len,params,init_gru_states,num_hiddens,vocab_size,device,idx_to_char,char_to_idx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:50,pre:108.79664,time:0\n",
      "--- 分开 我想你 你不了 我不要 我想你 我想你 我想你 我想你 我想你 我想你 我想你 我想你 我想你 我\n",
      "--- 不分开 我想你 你不了 我不要 我想你 我想你 我想你 我想你 我想你 我想你 我想你 我想你 我想你 我\n",
      "epoch:100,pre:12.11292,time:0\n",
      "--- 分开 我想要这样牵着你的手不放  爱在我以以以以单单没有                        \n",
      "--- 不分开 爱不不觉 经不再再不想 不知不觉 你已经这样奏 后知后觉 我的好好节活 让我不觉 你爱我 说你的甜\n",
      "epoch:150,pre:1.75199,time:0\n",
      "--- 分开 一个云酒 在人海中的溪边 情绪激动 一颗心到现在还在抽痛 还为分手前那句抱歉 在感动 穿梭时间的画\n",
      "--- 不分开 你已经离开我 不知不觉 我跟了这节奏 后知后觉 又过了一个秋 后知后觉 我该好好生活 我该好好生活\n",
      "epoch:200,pre:1.08422,time:0\n",
      "--- 分开 小弄事 废诉我 印地安的传说 还真是 瞎透了 什么都有 沙漠之中怎么会有泥鳅 话说完飞过一只海鸥 \n",
      "--- 不分开 整作云吗开嘛我有攻       古巴比伦王颁布了汉摩拉比法典 刻在黑色的玄武岩 距今已经三千七百多\n",
      "epoch:250,pre:1.03417,time:0\n",
      "--- 分开 小弄我 已沉为田手留白 所有人在莫铁铁香许下心愿 看远方的星如果听的见 它一定实现它一定实现 载著\n",
      "--- 不分开 你已经离开我 不知不觉 我跟了这节奏 后知后觉 后知后觉 迷迷蒙蒙 你给的梦 出现裂缝 隐隐作痛 \n"
     ]
    }
   ],
   "source": [
    "num_epochs =250\n",
    "num_steps = 35\n",
    "batch_size = 32\n",
    "lr =1e2\n",
    "clipping_theta = 1e-2\n",
    "pred_period = 50\n",
    "pred_len=50\n",
    "prefixes=['分开','不分开']\n",
    "train_and_pred_GRU(GRU,get_params,init_gru_states,num_hiddens,vocab_size,device,corpus_iter,\n",
    "char_to_idx,idx_to_char,False,num_epochs,num_steps,\n",
    "lr,clipping_theta,batch_size,pred_period,pred_len,prefixes)\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "2f394aca7ca06fed1e6064aef884364492d7cdda3614a461e02e6407fc40ba69"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
