{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn \n",
    "import numpy as np\n",
    "import sys\n",
    "import os\n",
    "import collections\n",
    "import random\n",
    "import math \n",
    "import torch.utils.data \n",
    "import time\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.10.0+cu113\n"
     ]
    }
   ],
   "source": [
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'#sentences:42068'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "assert 'ptb.train.txt' in os.listdir('/home/word2vec/data')\n",
    "with open('/home/word2vec/data/ptb.train.txt','r')as f:\n",
    "    lines = f.readlines()\n",
    "    raw_dataset = [st.split()for st in lines]\n",
    "'#sentences:%d'%(len(raw_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32481"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counter = collections.Counter([tk for st in raw_dataset for tk in st])\n",
    "counter = dict(filter(lambda x:x[1]>=5,counter.items()))\n",
    "counter['N']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_to_taken = [tk for tk,_ in counter.items()]\n",
    "token_to_idx = {tk:idx for idx,tk in enumerate(idx_to_taken)}\n",
    "dataset = [[token_to_idx[tk] for tk in st if tk in token_to_idx]for st in raw_dataset]\n",
    "num_tokens = sum([len(st)for st in dataset])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32481"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counter[idx_to_taken[2]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx_to_taken[2]\n",
    "token_to_idx['N']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "374934\n"
     ]
    }
   ],
   "source": [
    "def discard(idx):\n",
    "    return random.uniform(0,1)<1-math.sqrt(1e-4/counter[idx_to_taken[idx]]*num_tokens)\n",
    "sampled_data_set = [[tk for tk in st if not discard(tk)]for st in dataset]\n",
    "print(sum([len(st)for st in sampled_data_set]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'#the: before:50770,after:2174'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def compare_count(token):\n",
    "    return '#%s: before:%d,after:%d'%(token,sum([st.count(token_to_idx[token])for st in dataset]),sum([st.count(token_to_idx[token])for st in sampled_data_set]))\n",
    "compare_count('the')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_centers_and_contexts(dataset,max_window_size):\n",
    "    centers,contexts= [],[]\n",
    "    for st in dataset:\n",
    "        if len(st)<2:\n",
    "            continue\n",
    "        centers +=st\n",
    "        for center_i in range(len(st)):\n",
    "            window_size = random.randint(1,max_window_size)\n",
    "            indices = list(range(max(0,center_i-window_size),min(len(st),center_i+window_size+1)))\n",
    "            indices.remove(center_i)\n",
    "            contexts.append([st[idx]for idx in indices])\n",
    "    return centers,contexts\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset [[0, 1, 2, 3, 4, 5, 6], [7, 8, 9]]\n",
      "center: 0 has contexts: [1]\n",
      "center: 1 has contexts: [0, 2, 3]\n",
      "center: 2 has contexts: [0, 1, 3, 4]\n",
      "center: 3 has contexts: [1, 2, 4, 5]\n",
      "center: 4 has contexts: [3, 5]\n",
      "center: 5 has contexts: [4, 6]\n",
      "center: 6 has contexts: [5]\n",
      "center: 7 has contexts: [8, 9]\n",
      "center: 8 has contexts: [7, 9]\n",
      "center: 9 has contexts: [8]\n"
     ]
    }
   ],
   "source": [
    "tiny_dataset = [list(range(7)),list(range(7,10))]\n",
    "print('dataset',tiny_dataset)\n",
    "for centers,contexts in zip(*get_centers_and_contexts(tiny_dataset,2)):\n",
    "    print('center:',centers,'has contexts:',contexts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "374062 374062\n",
      "9858\n",
      "9858\n"
     ]
    }
   ],
   "source": [
    "all_centers,all_contexts = get_centers_and_contexts(sampled_data_set,5)\n",
    "print(len(all_centers),len(all_contexts))\n",
    "print(len(idx_to_taken))\n",
    "def get_negatives(all_contexts,sampling_weight,K):\n",
    "    all_negatives,neg_candidates,i= [],[],0\n",
    "    populations = list(range(len(sampling_weight)))\n",
    "    print(len(populations))\n",
    "    for contexts in all_contexts:\n",
    "        negatives= []\n",
    "        while len(negatives)<len(contexts)*K:\n",
    "            if i==len(neg_candidates):\n",
    "                i=0\n",
    "                neg_candidates  = random.choices(populations,sampling_weight,k = int(1e5))\n",
    "            neg =  neg_candidates[i]\n",
    "            i = i+1\n",
    "            if neg not in set(contexts):\n",
    "                negatives.append(neg)\n",
    "        all_negatives.append(negatives)\n",
    "    return all_negatives\n",
    "sampling_weight = [counter[w]**0.75 for w in idx_to_taken]\n",
    "all_negatives =  get_negatives(all_contexts,sampling_weight,K=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDateset(torch.utils.data.Dataset):\n",
    "    def __init__(self,centers,contexts,negatives):\n",
    "        assert len(centers)==len(contexts)==len(negatives)\n",
    "        self.centers = centers\n",
    "        self.contexts = contexts\n",
    "        self.negatives = negatives\n",
    "    def __getitem__(self,index):\n",
    "        return (self.centers[index],self.contexts[index],self.negatives[index])\n",
    "    def __len__(self):\n",
    "        return len(self.centers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batchify(data):\n",
    "    max_len = max(len(c)+len(n) for _,c,n in data)\n",
    "    centers,contexts_negatives,masks,labels =[],[],[],[]\n",
    "    for center,context,negative in data:\n",
    "        cur_len = len(context)+len(negative)\n",
    "        centers += [center]\n",
    "        contexts_negatives += [(context+negative+[0]*(max_len-cur_len))]\n",
    "        masks += [[1]*cur_len+[0]*(max_len-cur_len)]\n",
    "        labels += [[1]*len(contexts)+[0]*(max_len-len(contexts))]\n",
    "    return torch.tensor(centers).view(-1,1),torch.tensor(contexts_negatives),torch.tensor(masks),torch.tensor(labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([512, 1])\n",
      "torch.Size([512, 60])\n",
      "torch.Size([512, 60])\n",
      "torch.Size([512, 60])\n"
     ]
    }
   ],
   "source": [
    "batch_size=512\n",
    "num_workers = 0 \n",
    "dataset = MyDateset(all_centers,all_contexts,all_negatives)\n",
    "data_iter = torch.utils.data.DataLoader(dataset,batch_size=batch_size,num_workers=num_workers,shuffle=True,collate_fn=batchify)\n",
    "for batch in data_iter:\n",
    "    for name,data in zip(['centers','contexts_negative','mask','labels'],batch):\n",
    "        print(data.shape)\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.9626, -0.5621, -0.6834, -1.6152],\n",
       "         [ 2.0941,  1.1460, -0.2006, -2.0052],\n",
       "         [ 0.0125, -0.7882, -1.3902, -2.5942]],\n",
       "\n",
       "        [[-0.2524,  0.7251,  1.3045,  1.5416],\n",
       "         [ 1.0015, -1.8706, -1.6407, -0.6848],\n",
       "         [-1.0697,  1.1184, -0.5562, -0.2797]]], grad_fn=<EmbeddingBackward0>)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embed = nn.Embedding(num_embeddings=20,embedding_dim=4)\n",
    "x = torch.tensor([[1,2,3],[4,5,6]],dtype=torch.long)\n",
    "embed(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[4., 4., 4., 4., 4., 4.]],\n",
       "\n",
       "        [[4., 4., 4., 4., 4., 4.]]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.ones((2,1,4))\n",
    "y = torch.ones((2,4,6))\n",
    "torch.bmm(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def skip_gram(center,contexts_and_negatives,embed_v,embed_u):\n",
    "    v = embed_v(center)\n",
    "    u = embed_u(contexts_and_negatives)\n",
    "    pred = torch.bmm(v,u.permute(0,2,1))\n",
    "    return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SigmoidBinaryCrossEntropyLoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SigmoidBinaryCrossEntropyLoss,self).__init__()\n",
    "    def forward(self,inputs,targets,mask=None):\n",
    "        targets = targets.float()\n",
    "        mask = mask.float()\n",
    "        res = nn.functional.binary_cross_entropy_with_logits(inputs,targets,reduction=\"none\",weight=mask)\n",
    "        return res.mean(dim=1)\n",
    "        \n",
    "loss = SigmoidBinaryCrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.8740, 1.2100])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred =  torch.tensor([[1.5,0.3,-1,2],[1.1,-0.6,2.2,0.4]])\n",
    "labels = torch.tensor([[1,0,0,0],[1,1,0,0]])\n",
    "mask = torch.tensor([[1,1,1,1],[1,1,1,0]])\n",
    "loss(pred,labels,mask)*mask.shape[1]/mask.float().sum(dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(8.0389)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def sigmoid(x):\n",
    "    return 1/(1+np.exp(-x))\n",
    "loss = -labels*np.log(sigmoid(pred)) - (1-labels)*np.log(1-sigmoid(pred))\n",
    "loss.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8740\n"
     ]
    }
   ],
   "source": [
    "def sigmd(x):\n",
    "    return -math.log(1/(1+math.exp(-x)))\n",
    "print('%.4f'%((sigmd(1.5)+sigmd(-0.3)+sigmd(1)+sigmd(-2))/4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9858\n"
     ]
    }
   ],
   "source": [
    "print(len(idx_to_taken))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_size = 100\n",
    "net = nn.Sequential(\n",
    "    nn.Embedding(num_embeddings=len(idx_to_taken),embedding_dim=embed_size),\n",
    "    nn.Embedding(num_embeddings=len(idx_to_taken),embedding_dim=embed_size)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(net,lr,num_epochs):\n",
    "    device =torch.device('cuda' if torch.cuda.is_available()else 'cpu')\n",
    "    net= net.to(device)\n",
    "    print('trian on:',device)\n",
    "    optimizer = torch.optim.Adam(net.parameters(),lr=lr)\n",
    "    for epoch in range(num_epochs):\n",
    "        start = time.time()\n",
    "        train_loss = 0.0\n",
    "        n = 0\n",
    "        for batch in data_iter:\n",
    "            centers,contexts_negatives,mask,labels = [b.to(device)for b in batch]\n",
    "            pred = skip_gram(centers,contexts_negatives,net[0],net[1])\n",
    "            l = (loss(pred.view(labels.shape),labels,mask)*mask.shape[1]/mask.float().sum(dim=1)).mean()\n",
    "            optimizer.zero_grad()\n",
    "            l.backward()\n",
    "            optimizer.step()\n",
    "            train_loss += l.cpu().item()\n",
    "            n +=1\n",
    "        print('epoch:%d,loss:%.4f,time:%.2f'%(epoch+1,train_loss/n,time.time()-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trian on: cuda\n",
      "epoch:1,loss:0.2053,time:6.23\n",
      "epoch:2,loss:0.1629,time:6.64\n",
      "epoch:3,loss:0.1474,time:6.69\n",
      "epoch:4,loss:0.1384,time:6.85\n",
      "epoch:5,loss:0.1320,time:6.80\n",
      "epoch:6,loss:0.1273,time:6.28\n",
      "epoch:7,loss:0.1237,time:6.59\n",
      "epoch:8,loss:0.1208,time:6.88\n",
      "epoch:9,loss:0.1184,time:6.59\n",
      "epoch:10,loss:0.1164,time:6.47\n"
     ]
    }
   ],
   "source": [
    "train(net,0.01,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cosine sim=1.000:chip\n",
      "cosine sim=0.465:recovery\n",
      "cosine sim=0.458:roads\n",
      "cosine sim=0.442:plunging\n"
     ]
    }
   ],
   "source": [
    "def get_similar_tokens(query_token,k,embed):\n",
    "    W = embed.weight.data\n",
    "    x = W[token_to_idx[query_token]]\n",
    "    cos = torch.matmul(W,x)/(torch.sum(W*W,dim=1)*torch.sum(x*x)+1e-9).sqrt()\n",
    "    _,topk = torch.topk(cos,k=k+1)\n",
    "    topk = topk.cpu().numpy()\n",
    "    for i in topk[:]:\n",
    "        print('cosine sim=%.3f:%s'%(cos[i],(idx_to_taken[i])))\n",
    "get_similar_tokens('chip',3,net[0])   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sat May  7 12:15:12 2022       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 510.60.02    Driver Version: 510.60.02    CUDA Version: 11.6     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  NVIDIA RTX A5000    On   | 00000000:81:00.0 Off |                  Off |\n",
      "| 30%   31C    P8    14W / 230W |      0MiB / 24564MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|  No running processes found                                                 |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "2f394aca7ca06fed1e6064aef884364492d7cdda3614a461e02e6407fc40ba69"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
